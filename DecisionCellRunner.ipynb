{
 "cells": [
  {
   "cell_type": "code",
   "id": "bc546ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:08:30.958823Z",
     "start_time": "2026-01-11T12:08:25.656559Z"
    }
   },
   "source": [
    "# Core imports \n",
    "from core.DecisionCell import DecisionCell\n",
    "from core.Tooling import ToolHandler, ToolRegistry\n",
    "from core.Agent import Agent\n",
    "\n",
    "# Tooling imports\n",
    "from tools.KnowledgeBaseTool import KnowledgeBaseTool\n",
    "from tools.AskHumanTool import AskHumanTool"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3a670d79",
   "metadata": {},
   "source": [
    "# DecisionCell  \n",
    "A modular multi-agent framework for transparent, tool-augmented decision making\n",
    "\n",
    "DecisionCell is a proof-of-concept multi-agent decision framework designed to support\n",
    "collaborative reasoning through transparency and tool use.  \n",
    "It enables multiple agents to think, act, call tools, and exchange observations\n",
    "to collectively analyze a problem or objective.\n",
    "\n",
    "The system combines:\n",
    "\n",
    "- **ReAct-style reasoning** – agents think, take structured actions, call tools, and react to observations  \n",
    "- **Transparent reasoning traces** – each agent exposes its step-by-step thought process  \n",
    "- **Retrieval-Augmented Generation (RAG)** – agents can query their own knowledge bases to ground reasoning in data  \n",
    "\n",
    "This notebook walks you through the full setup required to run a DecisionCell experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167c2ee",
   "metadata": {},
   "source": [
    "## 1. Set up the staff (agents)\n",
    "\n",
    "DecsionCell works with a small “staff” of collaborating agents. Each agent is defined by:\n",
    "\n",
    "- A **role** (e.g. Commander, Intelligence, Logistics) encoded in a **system prompt**.\n",
    "- A **provider** and **model** (e.g., Ollama (or HF) + Llama 3)\n",
    "- Optional **tools** it can call (e.g. knowledge base, online search)\n",
    "\n",
    "In the next cell we instantiate these agents and collect them in a staff list. \n",
    "\n",
    "### Provider Setup\n",
    "\n",
    "You can run agents using either **Ollama (local models)** or **Hugging Face (cloud models)**.\n",
    "\n",
    "#### **Using Ollama **  \n",
    "Make sure the model is available and the service is running (see cell bellow)\n",
    "\n",
    "#### **Using HF**  \n",
    "Make sure to set your Hugging Face API key before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3c5da38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:08:30.962797Z",
     "start_time": "2026-01-11T12:08:30.961336Z"
    }
   },
   "source": [
    "# Pull the models to be used for the agents\n",
    "# !ollama pull qwen2.5:7b-instruct\n",
    "\n",
    "# Confirm the ollama service is running\n",
    "# !ollama list"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f191a232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:08:31.065682Z",
     "start_time": "2026-01-11T12:08:31.061981Z"
    }
   },
   "source": [
    "# Build the staff list\n",
    "staff = [\n",
    "    # Agent(\"Commander\", provider=\"ollama\", model=\"qwen2.5:7b-instruct\", debug=True),\n",
    "    # Agent(\"LegalAdvisor\", provider=\"ollama\", model=\"qwen2.5:7b-instruct\", debug=True),\n",
    "    Agent(\"Commander\", provider=\"hf\", model=\"HuggingFaceH4/zephyr-7b-beta\"),\n",
    "    Agent(\"LegalAdvisor\", provider=\"hf\", model=\"HuggingFaceH4/zephyr-7b-beta\"),\n",
    "]\n",
    "\n",
    "commander = staff[0]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c15e2edb",
   "metadata": {},
   "source": [
    "Now that the agents are defined, we specify which tools they can use. Tools extend an agent’s capabilities beyond pure language modeling. For example, a tool may allow an agent to:\n",
    "\n",
    "- Search its own knowledge base  \n",
    "- Query external information  \n",
    "- Ask a human for clarification  \n",
    "\n",
    "Tools are declared in the `AGENT_TOOLS` list. By registering these tools with the `ToolRegistry`, we enable the agents to call them dynamically through structured actions.The `ToolHandler` is then responsible for routing each tool call to the correct tool implementation."
   ]
  },
  {
   "cell_type": "code",
   "id": "1c8a1ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:09:12.072912Z",
     "start_time": "2026-01-11T12:08:31.069324Z"
    }
   },
   "source": [
    "AGENT_TOOLS = [\n",
    "    KnowledgeBaseTool(agent=\"LegalAdvisor\", k=3, embedding_model = \"normal\", chunk_size=512, chunk_overlap=100),\n",
    "    AskHumanTool(\"LegalAdvisor\"), \n",
    "    AskHumanTool(\"Commander\"),\n",
    "]\n",
    "\n",
    "registry = ToolRegistry(AGENT_TOOLS)\n",
    "handler = ToolHandler(registry)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 13:08:35,401 - INFO - Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b20c59db7b8d4ba6a77be29f9b5c912b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6eed1753053a45f9b69ccb97a350c804"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4f7247c0bfe4c89abc93e0561f14e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5982aa79483942a18df8681e5eb84a86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "793f0f39e791422cbf8e8fff3df0213b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fda6a8adf4d240219ea5f56524ca04ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f64373485edf46648b2272f82691839a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42757e0b54014d1ab66b9e83bf2f88aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ea4c0c3bf1b47deb793a4628306a0fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a15a78c795294baf9e2ae625d3cba6b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d9a302836fd4063b83d43a7e0f18c48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 13:08:43,856 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "907a74a5",
   "metadata": {},
   "source": [
    "## 2. Construct the DecisionCell (orchestrator)\n",
    "\n",
    "The `DecisionCell` is the central orchestrator, it:\n",
    "\n",
    "- Keeps track of the **conversation state** and the message stack.\n",
    "- Decides **which agent acts next**.\n",
    "- Routes **tool calls** through the `ToolHandler`.\n",
    "- Stops when the objective is solved or the **max_turns** limit is reached.\n",
    "\n",
    "In the next cell we create a `DecisionCell` by passing:\n",
    "- The full `staff` list.\n",
    "- The designated `commander` agent.\n",
    "- The shared `tool_handler`.\n",
    "- Some runtime settings such as `max_turns` and `debug`."
   ]
  },
  {
   "cell_type": "code",
   "id": "e648a7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:09:12.079448Z",
     "start_time": "2026-01-11T12:09:12.077804Z"
    }
   },
   "source": [
    "cell = DecisionCell(\n",
    "    agents=staff,\n",
    "    commander=commander,\n",
    "    tool_handler=handler,\n",
    "    max_turns=20,\n",
    "    debug=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "4662ebda",
   "metadata": {},
   "source": [
    "## 3. Define the mission objective\n",
    "\n",
    "The mission objective describes the operational problem to be analyzed.\n",
    "\n",
    "The objective is expressed as a multi-line natural-language description that\n",
    "outlines the scenario and available Courses of Action (CoAs).  This text becomes \n",
    "the first input to the Commander when the decision process begins."
   ]
  },
  {
   "cell_type": "code",
   "id": "fc569de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:09:12.086514Z",
     "start_time": "2026-01-11T12:09:12.084837Z"
    }
   },
   "source": [
    "objective = \"\"\" \n",
    "Conduct a counter-terrorism cyber operation by a coalition of 12 countries to prevent an imminent attack by the Terrmisous group on a commercial cargo ship carrying chemical agents near the civilian port AricikPortus.\n",
    "\n",
    "CoA 1: Disable the VicikPortus power grid using a previously implanted BlackEnergy3-based malware to prevent the terrorists from loading their cargo ship.\n",
    "CoA 2: Temporarily neutralize the VicikPortus civilian pump station using a DDoS attack exploiting an unpatched vulnerability, preventing fueling of the terrorist vessel.\n",
    "CoA 3: Conduct GNSS spoofing to alter the cargo ship's position, velocity, and heading after departure so it cannot reach its intended target.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "4b454bf3",
   "metadata": {},
   "source": [
    "## 4. Run the decision cycle\n",
    "\n",
    "With the staff, tools, and mission objective defined, we can now execute the full\n",
    "decision cycle.  \n",
    "The `DecisionCell` sends the objective to the Commander, who begins the analysis\n",
    "and may consult other agents or call tools as needed.\n",
    "\n",
    "During the cycle:\n",
    "\n",
    "- Agents reason using the ReAct loop  \n",
    "- Tool calls (e.g., knowledge base search or asking a human) are invoked when required  \n",
    "- Observations are fed back into the agents' thinking  \n",
    "- The process continues until a final recommendation is produced or the turn limit is reached  \n",
    "\n",
    "The output includes:\n",
    "- **RESULT** — the final recommendation from the Commander  \n",
    "- **TRACE** — a step-by-step record of the agent actions and observations for transparency "
   ]
  },
  {
   "cell_type": "code",
   "id": "fda13383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:09:41.535804Z",
     "start_time": "2026-01-11T12:09:12.091128Z"
    }
   },
   "source": [
    "logbook = cell.run(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908abf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "text = logbook.console.export_text()\n",
    "\n",
    "# HTML\n",
    "html = logbook.console.export_html(inline_styles=True)\n",
    "\n",
    "# Raw trace\n",
    "trace = logbook.trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
